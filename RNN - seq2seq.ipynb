{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN - seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qN0ILJQojgA"
      },
      "source": [
        "Sequence to Sequence  \n",
        "https://wikidocs.net/24996"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50mebhC5oXcw"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIRPXOgL460L"
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
        "    shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjVWxCsi4_sU",
        "outputId": "80b58840-f9f2-4ec9-84df-773fdb8c556a"
      },
      "source": [
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "del lines['lic']\n",
        "len(lines)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190206"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YL9EHVfL5Cc9",
        "outputId": "ff96bad6-fded-41ef-ab70-326a2f881899"
      },
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45751</th>\n",
              "      <td>You overestimate him.</td>\n",
              "      <td>Vous le surestimez.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46882</th>\n",
              "      <td>Everyone kept talking.</td>\n",
              "      <td>Tout le monde continua à parler.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10851</th>\n",
              "      <td>Is this common?</td>\n",
              "      <td>C'est courant ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15404</th>\n",
              "      <td>They both smile.</td>\n",
              "      <td>Elles sourient toutes les deux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46611</th>\n",
              "      <td>Do you recognize them?</td>\n",
              "      <td>Les reconnaissez-vous ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21209</th>\n",
              "      <td>What's your name?</td>\n",
              "      <td>Comment t'appelles-tu ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32670</th>\n",
              "      <td>Would you like ice?</td>\n",
              "      <td>Voudriez-vous de la glace ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20704</th>\n",
              "      <td>Tom went fishing.</td>\n",
              "      <td>Tom est parti pêcher.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3291</th>\n",
              "      <td>I'm curious.</td>\n",
              "      <td>Je suis curieux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48524</th>\n",
              "      <td>I respect your talent.</td>\n",
              "      <td>Je respecte votre talent.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          src                               tar\n",
              "45751   You overestimate him.               Vous le surestimez.\n",
              "46882  Everyone kept talking.  Tout le monde continua à parler.\n",
              "10851         Is this common?                   C'est courant ?\n",
              "15404        They both smile.   Elles sourient toutes les deux.\n",
              "46611  Do you recognize them?           Les reconnaissez-vous ?\n",
              "21209       What's your name?           Comment t'appelles-tu ?\n",
              "32670     Would you like ice?       Voudriez-vous de la glace ?\n",
              "20704       Tom went fishing.             Tom est parti pêcher.\n",
              "3291             I'm curious.                  Je suis curieux.\n",
              "48524  I respect your talent.         Je respecte votre talent."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6Lu267MO5Ez8",
        "outputId": "04bec9dc-a034-4e42-e8ca-9ca8cba984dd"
      },
      "source": [
        "# 번역되는 프랑스어에 시작을 의미하는 심볼 <sos>과 종료를 의미하는 심볼 <eos> 추가\n",
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5256</th>\n",
              "      <td>Is it cloudy?</td>\n",
              "      <td>\\t Est-ce nuageux ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32423</th>\n",
              "      <td>When do you get up?</td>\n",
              "      <td>\\t À quelle heure te lèves-tu ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16665</th>\n",
              "      <td>You're forgiven.</td>\n",
              "      <td>\\t Vous êtes pardonnées. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34749</th>\n",
              "      <td>I don't want dinner.</td>\n",
              "      <td>\\t Je ne veux pas souper. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48128</th>\n",
              "      <td>I have pain in my arm.</td>\n",
              "      <td>\\t J'ai une douleur au bras. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19781</th>\n",
              "      <td>Take it upstairs.</td>\n",
              "      <td>\\t Emmenez-le à l'étage. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12026</th>\n",
              "      <td>Try to do that.</td>\n",
              "      <td>\\t Essaie de faire cela. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6168</th>\n",
              "      <td>What a woman!</td>\n",
              "      <td>\\t Quelle femme ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32767</th>\n",
              "      <td>You had a long day.</td>\n",
              "      <td>\\t Vous avez eu une longue journée. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54212</th>\n",
              "      <td>He's out taking a walk.</td>\n",
              "      <td>\\t Il est dehors en train de se promener. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           src                                           tar\n",
              "5256             Is it cloudy?                        \\t Est-ce nuageux ? \\n\n",
              "32423      When do you get up?            \\t À quelle heure te lèves-tu ? \\n\n",
              "16665         You're forgiven.                   \\t Vous êtes pardonnées. \\n\n",
              "34749     I don't want dinner.                  \\t Je ne veux pas souper. \\n\n",
              "48128   I have pain in my arm.               \\t J'ai une douleur au bras. \\n\n",
              "19781        Take it upstairs.                   \\t Emmenez-le à l'étage. \\n\n",
              "12026          Try to do that.                   \\t Essaie de faire cela. \\n\n",
              "6168             What a woman!                          \\t Quelle femme ! \\n\n",
              "32767      You had a long day.        \\t Vous avez eu une longue journée. \\n\n",
              "54212  He's out taking a walk.  \\t Il est dehors en train de se promener. \\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e3ZCbsc5MUg"
      },
      "source": [
        "# 글자 집합 구축\n",
        "src_vocab=set()\n",
        "for line in lines.src: # 1줄씩 읽음\n",
        "    for char in line: # 1개의 글자씩 읽음\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab=set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqxfS8wr5e8s",
        "outputId": "f04784d5-d2e8-44a1-b97e-2d16add821ba"
      },
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print(src_vocab_size)\n",
        "print(tar_vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n",
            "105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10qLsfhH5hBm",
        "outputId": "0b4c8277-5c01-45d3-a709-ef1be5417eb5"
      },
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCvr44YE5nOw",
        "outputId": "bc4d2bde-4251-4665-dfe1-d5070a407b88"
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_avDqDmm5pa4",
        "outputId": "300127a8-19ef-46bf-a1c6-09a4856d90a3"
      },
      "source": [
        "# 정수 인코딩\n",
        "# 인코더 - 영어 데이터\n",
        "encoder_input = []\n",
        "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
        "    temp_X = []\n",
        "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
        "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
        "    encoder_input.append(temp_X)\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv0xvsdw5smV",
        "outputId": "1852be66-ba24-4897-a443-5bad2ae913c4"
      },
      "source": [
        "# 디코더 - 프랑스어 데이터 (예측값)\n",
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      temp_X.append(tar_to_index[w])\n",
        "    decoder_input.append(temp_X)\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Im_WW3n5xHQ",
        "outputId": "2063fad6-7c57-4b43-a3b1-720d899ad2c7"
      },
      "source": [
        "# 디코더 - 프랑스어 데이터 (실제값) : 시작 심볼에 해당되는 <sos>가 있을 필요가 없음\n",
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "    t=0\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      if t>0:\n",
        "        temp_X.append(tar_to_index[w])\n",
        "      t=t+1\n",
        "    decoder_target.append(temp_X)\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goQQOs4r6cWD",
        "outputId": "a0de175c-f957-4e0c-ccd9-2cc6fec4299b"
      },
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uWZqYyH6eMh"
      },
      "source": [
        "# padding 으로 각 샘플들 길이 맞추기\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUoDRE_Q6rig"
      },
      "source": [
        "# one-hot encoding\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpHQ_Jtv6wB8"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnVpVfia65aF"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
        "encoder_states = [state_h, state_c]\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4RLLp_c670g"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTtn2z1J6-Qh",
        "outputId": "3fea5db2-3a5a-44b3-dd93-838c8369295b"
      },
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 40s 44ms/step - loss: 0.7476 - val_loss: 0.6603\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.4553 - val_loss: 0.5337\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.3823 - val_loss: 0.4718\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.3398 - val_loss: 0.4338\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3121 - val_loss: 0.4091\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.2915 - val_loss: 0.3927\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2756 - val_loss: 0.3791\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2626 - val_loss: 0.3709\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2520 - val_loss: 0.3642\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2426 - val_loss: 0.3624\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2344 - val_loss: 0.3559\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2270 - val_loss: 0.3522\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.2205 - val_loss: 0.3514\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2144 - val_loss: 0.3493\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2089 - val_loss: 0.3481\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.2038 - val_loss: 0.3486\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1990 - val_loss: 0.3506\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1945 - val_loss: 0.3509\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1904 - val_loss: 0.3495\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1865 - val_loss: 0.3498\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1828 - val_loss: 0.3523\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1793 - val_loss: 0.3557\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1759 - val_loss: 0.3551\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1727 - val_loss: 0.3562\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1698 - val_loss: 0.3600\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1669 - val_loss: 0.3595\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.1642 - val_loss: 0.3640\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1616 - val_loss: 0.3641\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1590 - val_loss: 0.3662\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1566 - val_loss: 0.3686\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1543 - val_loss: 0.3715\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1522 - val_loss: 0.3735\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1500 - val_loss: 0.3770\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1481 - val_loss: 0.3795\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1460 - val_loss: 0.3815\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1441 - val_loss: 0.3847\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1422 - val_loss: 0.3865\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1406 - val_loss: 0.3888\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1387 - val_loss: 0.3937\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1371 - val_loss: 0.3934\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1356 - val_loss: 0.3989\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1341 - val_loss: 0.3993\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1326 - val_loss: 0.4005\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1311 - val_loss: 0.4032\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1299 - val_loss: 0.4072\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1284 - val_loss: 0.4106\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1271 - val_loss: 0.4125\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1259 - val_loss: 0.4156\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1246 - val_loss: 0.4161\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.1233 - val_loss: 0.4196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5ac16df10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBUo0R-27Akc"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPJTzYZeBXv3"
      },
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZfxEo7OBa4U"
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6YQXV0MBqgl"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIUbJ28qBtdf",
        "outputId": "1a77e0da-d534-4904-c578-3734a5cfba2d"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.src[seq_index])\n",
        "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "입력 문장: Hi.\n",
            "정답 문장:  Salut ! \n",
            "번역기가 번역한 문장:  Salut ! \n",
            "-----------------------------------\n",
            "입력 문장: I see.\n",
            "정답 문장:  Aha. \n",
            "번역기가 번역한 문장:  Je l'ai trouvé. \n",
            "-----------------------------------\n",
            "입력 문장: Hug me.\n",
            "정답 문장:  Serrez-moi dans vos bras ! \n",
            "번역기가 번역한 문장:  Serrez-moi dans les yeux. \n",
            "-----------------------------------\n",
            "입력 문장: Hold it!\n",
            "정답 문장:  Restez où vous êtes ! \n",
            "번역기가 번역한 문장:  Ne bouge plus ! \n",
            "-----------------------------------\n",
            "입력 문장: I crashed.\n",
            "정답 문장:  Je me suis écrasée. \n",
            "번역기가 번역한 문장:  Je me suis fité. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E3ZUbznBvt3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}